# SprintSync

> Lean internal tool for engineers: log work, track time, and get AI-powered planning help.  
> Built as the CodeStratLabs hiring challenge reference implementation.

[![CI](https://github.com/YOUR_USERNAME/sprintsync/actions/workflows/ci.yml/badge.svg)](https://github.com/YOUR_USERNAME/sprintsync/actions)

---

## ğŸ¥ Demo Video

[Loom walkthrough â€” 5 min](https://drive.google.com/file/d/1neCTI4XO-xQwtD3tM95Iaf2HQOK6q8Ix/view?usp=drivesdk)  
Covers: product demo â†’ architecture â†’ code tour â†’ deploy.

## ğŸŒ Live App

[https://sprintsync.onrender.com](https://sprintsync.onrender.com)

Demo credentials:
- `alice / alice123` (regular user)
- `admin / admin123` (admin)

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               SprintSync                    â”‚
â”‚                                             â”‚
â”‚  React SPA (Vite)  â†â†’  FastAPI backend      â”‚
â”‚                         â”‚                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”              â”‚
â”‚                    â”‚ SQLite  â”‚ (dev)        â”‚
â”‚                    â”‚Postgres â”‚ (prod)       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                             â”‚
â”‚  AI: OpenAI gpt-4o-mini  (+ stub fallback) or coustom modelâ”‚
â”‚  Auth: JWT (python-jose + bcrypt)           â”‚
â”‚  Logging: structlog JSON â†’ stdout           â”‚
â”‚  Metrics: /metrics (Prometheus-style JSON)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key design decisions:**

- **FastAPI** chosen for: automatic OpenAPI/Swagger docs, async support for AI calls, Pydantic validation, minimal boilerplate.
- **SQLite in dev / Postgres in prod** via a single `DATABASE_URL` env var â€” no code changes needed.
- **AI stub pattern**: `USE_AI_STUB=true` returns deterministic JSON. The same code path is used in tests and CI, ensuring the integration test doesn't depend on external APIs.
- **Status state machine**: `STATUS_TRANSITIONS` dict in the model layer enforces valid transitions (backlog â†’ in_progress â†’ review â†’ done). Invalid transitions return a descriptive 400 with allowed next states.
- **Middleware logging**: every request logs `method, path, userId, latency_ms` as structured JSON. Stack traces appear on errors. `/metrics` exposes in-memory counters.

---

## Project Structure

```
sprintsync/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI app, middleware, startup
â”‚   â”œâ”€â”€ config.py            # Pydantic settings (env vars)
â”‚   â”œâ”€â”€ database.py          # SQLAlchemy engine + session
â”‚   â”œâ”€â”€ seed.py              # Demo data seeder
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ user.py          # User model (isAdmin)
â”‚   â”‚   â””â”€â”€ task.py          # Task model + STATUS_TRANSITIONS
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ auth.py          # /auth/register, /auth/token
â”‚   â”‚   â”œâ”€â”€ users.py         # CRUD /users
â”‚   â”‚   â”œâ”€â”€ tasks.py         # CRUD /tasks + /transition
â”‚   â”‚   â”œâ”€â”€ ai.py            # /ai/suggest (description | daily_plan)
â”‚   â”‚   â””â”€â”€ stats.py         # /stats/top-users, /stats/cycle-time
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ auth.py          # JWT, password hashing, get_current_user
â”‚   â”‚   â”œâ”€â”€ ai.py            # OpenAI calls + deterministic stub
â”‚   â”‚   â””â”€â”€ logging.py       # structlog config, metrics, middleware
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ conftest.py      # Fixtures, in-memory DB override
â”‚   â”‚   â”œâ”€â”€ test_unit.py     # 2+ happy path unit tests
â”‚   â”‚   â””â”€â”€ test_integration.py # /ai/suggest stub integration test
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx          # Full React SPA (list + kanban views)
â”‚   â”‚   â””â”€â”€ api.js           # API client with token management
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ .github/workflows/ci.yml # GitHub Actions: lint â†’ test â†’ docker build
â”œâ”€â”€ Dockerfile               # Multi-stage: Node (frontend) + Python
â”œâ”€â”€ docker-compose.yml       # App + Postgres
â”œâ”€â”€ docker-compose.dev.yml   # App + SQLite (simpler local dev)
â”œâ”€â”€ render.yaml              # One-click Render deploy
â”œâ”€â”€ estimates.csv            # Time estimates vs actuals
â””â”€â”€ README.md
```

---

## Quick Start

### Local dev (Python + Node, no Docker)

```bash
# Backend
cd backend
pip install -r requirements.txt
cp ../.env.example .env
# Edit .env if needed (defaults use SQLite, stub AI)
uvicorn main:app --reload
# â†’ http://localhost:8000 (API + Swagger at /docs)

# Frontend (separate terminal)
cd frontend
npm install
npm run dev
# â†’ http://localhost:5173
```

### Docker (recommended)

```bash
cp .env.example .env
# Optionally add OPENAI_API_KEY=sk-...
docker-compose up --build
# â†’ http://localhost:8000
```

---

## API Reference

Full interactive docs at `/docs` (Swagger) or `/redoc`.

| Method | Endpoint | Auth | Description |
|--------|----------|------|-------------|
| POST | `/auth/register` | â€” | Register new user |
| POST | `/auth/token` | â€” | Login â†’ JWT |
| GET | `/users/me` | JWT | Current user profile |
| GET | `/users/` | Admin | List all users |
| GET | `/tasks/` | JWT | List tasks (own, or all if admin) |
| POST | `/tasks/` | JWT | Create task |
| PATCH | `/tasks/{id}` | JWT | Update task fields |
| POST | `/tasks/{id}/transition` | JWT | Status transition |
| DELETE | `/tasks/{id}` | JWT | Delete task |
| POST | `/ai/suggest?mode=description&title=...` | JWT | AI task description |
| POST | `/ai/suggest?mode=daily_plan` | JWT | AI daily plan |
| GET | `/stats/top-users` | JWT | Top 5 users by minutes |
| GET | `/stats/cycle-time` | JWT | Avg minutes per status |
| GET | `/metrics` | â€” | Prometheus-style JSON metrics |
| GET | `/health` | â€” | Health check |

---

## Testing

```bash
cd backend
# All tests (uses in-memory SQLite + AI stub, no external services needed)
pytest tests/ -v

# Expected output:
# tests/test_unit.py::TestAuth::test_register_and_login PASSED
# tests/test_unit.py::TestAuth::test_login_wrong_password PASSED
# tests/test_unit.py::TestAuth::test_get_me PASSED
# tests/test_unit.py::TestTasks::test_create_and_list_tasks PASSED
# tests/test_unit.py::TestTasks::test_status_transition_happy_path PASSED
# tests/test_unit.py::TestTasks::test_invalid_status_transition PASSED
# tests/test_unit.py::TestTasks::test_update_task PASSED
# tests/test_unit.py::TestTasks::test_delete_task PASSED
# tests/test_integration.py::TestAISuggestIntegration::test_suggest_description_stub PASSED
# tests/test_integration.py::TestAISuggestIntegration::test_suggest_daily_plan_stub PASSED
# tests/test_integration.py::TestAISuggestIntegration::test_suggest_description_missing_title PASSED
# tests/test_integration.py::TestAISuggestIntegration::test_suggest_unauthenticated PASSED
```

---

## Deployment (Render)

1. Push to GitHub
2. Go to [render.com](https://render.com) â†’ New â†’ Blueprint
3. Point to this repo â€” Render reads `render.yaml` automatically
4. Set `OPENAI_API_KEY` in Render dashboard (optional; stub works without it)
5. Deploy â€” first run seeds demo data automatically

---

## Observability

**Structured logs** (stdout, JSON):
```json
{"level": "info", "logger": "sprintsync", "timestamp": "2026-02-24T10:00:00Z",
 "event": "request", "method": "POST", "path": "/tasks/", "status_code": 201,
 "latency_ms": 12.4, "user_id": 2}
```

**Metrics** (`GET /metrics`):
```json
{
  "requests_total": 142,
  "requests_by_status_200": 130,
  "requests_by_status_201": 8,
  "requests_by_status_401": 4,
  "latency_ms_total": 1840.2
}
```

---

## Stretch Features Implemented

- âœ… **React SPA** â€” List view + Kanban board, task CRUD, AI assist, auth
- âœ… **CI pipeline** â€” GitHub Actions: test â†’ docker build on every push
- âœ… `/stats/top-users` â€” Top 5 by logged minutes
- âœ… `/stats/cycle-time` â€” Average minutes per task status
- âœ… `render.yaml` â€” One-click Render deployment blueprint

---

## Time Log

See `estimates.csv` for task-by-task estimates vs actuals.

---

*Built with FastAPI Â· React Â· SQLAlchemy Â· structlog Â· OpenAI Â· Docker*
